# AIAgentForge/state/lresearch_state.py

import reflex as rx
# build_agent_graphë¥¼ ì§ì ‘ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from AIAgentForge.agents.lresearcher import build_agent_graph
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class LResearchState(rx.State):
    """
    Local Deep Researcher í˜ì´ì§€ì˜ ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    # ì‚¬ìš©ì ì…ë ¥ì„ ìœ„í•œ ë³€ìˆ˜
    query: str = ""
    
    # ìµœì¢… ë³´ê³ ì„œë¥¼ ì €ì¥í•  ë³€ìˆ˜
    report: str = ""
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰ ì—¬ë¶€ë¥¼ ì¶”ì í•˜ëŠ” ë³€ìˆ˜ (UI ë¡œë”© ìƒíƒœ í‘œì‹œìš©)
    is_running: bool = False
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰ ìƒíƒœ ë©”ì‹œì§€ (ì§„í–‰ ìƒí™©ì„ í‘œì‹œ)
    status_message: str = ""

    async def start_research(self):
        """
        ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        if not self.query.strip():
            # ì…ë ¥ì´ ì—†ì„ ê²½ìš° ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ
            return
        
        # ì´ì „ ê²°ê³¼ ì´ˆê¸°í™” ë° ì‹¤í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.is_running = True
        self.report = ""
        self.status_message = "ë¦¬ì„œì¹˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤... (ìµœëŒ€ ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"
        
        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì—ì´ì „íŠ¸ ì‹¤í–‰
        # UIê°€ ë©ˆì¶”ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
        return type(self).run_agent_background

    @rx.event(background=True)
    async def run_agent_background(self):
        """
        ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ê·¸ë˜í”„ë¥¼ ë‹¨ê³„ë³„ë¡œ ì‹¤í–‰í•˜ê³  UI ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        """
        try:
            async with self:
                self.status_message = "ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤..."
            
            # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤.
            graph = build_agent_graph()
            initial_state = {"query": self.query, "plan": "", "drafts": [], "critiques": [], "report": ""}

            final_state = None
            # graph.astream()ì„ ì‚¬ìš©í•˜ì—¬ ê° ë‹¨ê³„ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ìˆœíšŒí•©ë‹ˆë‹¤.
            # ê° ë‹¨ê³„ì˜ ì¶œë ¥ì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ UIë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            async for step_output in graph.astream(initial_state):
                # step_outputì€ {'node_name': state_update} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
                node_name = list(step_output.keys())[0]
                
                # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ë…¸ë“œì— ë”°ë¼ ìƒíƒœ ë©”ì‹œì§€ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                async with self:
                    if node_name == "planner":
                        self.status_message = "âœ… 1/3: ë¦¬ì„œì¹˜ ê³„íšì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."
                    elif node_name == "researcher":
                        self.status_message = "âœ… 2/3: ì›¹ ê²€ìƒ‰ ë° ì´ˆì•ˆì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."
                    elif node_name == "reporter":
                        self.status_message = "âœ… 3/3: ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."
                
                # ë§ˆì§€ë§‰ ìƒíƒœë¥¼ ê³„ì†í•´ì„œ ì €ì¥í•©ë‹ˆë‹¤.
                final_state = step_output

            # ìµœì¢… ê²°ê³¼ ì¶”ì¶œ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
            # ë§ˆì§€ë§‰ ë…¸ë“œ('reporter')ì˜ ê²°ê³¼ì—ì„œ ë³´ê³ ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            report_result = final_state['reporter'].get("report", "ë³´ê³ ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            async with self:
                self.report = report_result
                self.is_running = False
                self.status_message = "ğŸ‰ ë¦¬ì„œì¹˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
                
        except Exception as e:
            async with self:
                self.report = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                self.is_running = False
                self.status_message = "ì˜¤ë¥˜ë¡œ ì¸í•´ ë¦¬ì„œì¹˜ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."
            logging.error(f"Background task error: {e}")

